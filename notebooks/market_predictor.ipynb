{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pgtaa import config as cfg\n",
    "from pgtaa.core.utils import read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshaped_data(df: pd.DataFrame, window_size: int=100, pred_range: int=5, scaler=None):\n",
    "    x = df.copy()\n",
    "    y = df.iloc[:, :8] # select prediction labels\n",
    "    y = np.log(y.pct_change(pred_range) + 1)\n",
    "    y = y.values[pred_range + 1:]\n",
    "    x.iloc[:, :8] = x.iloc[:, :8].pct_change(1)\n",
    "    x = x[1:-pred_range]\n",
    "    try:\n",
    "        x = scaler.transform(x) # scaler has to be fitted already\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    xdata, ydata = [], []\n",
    "    for step in range(x.shape[0] - window_size):\n",
    "        xdata.append(x[step: window_size + step])\n",
    "        ydata.append(y[window_size + step: window_size + step + 1])\n",
    "        \n",
    "    xdata = np.array(xdata)\n",
    "    ydata = np.array(ydata).reshape((x.shape[0] - window_size, y.shape[1]))\n",
    "    \n",
    "    # xdata has the shape (samples, window_size, columns)\n",
    "    # ydata has the shape (samples, nb_assets)\n",
    "    return xdata, ydata\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, xdata, ydata):\n",
    "        super(TimeSeriesDataset, self).__init__()\n",
    "        self.xdata = xdata\n",
    "        self.ydata = ydata\n",
    "        \n",
    "    def __getitem__(self, x):\n",
    "        return torch.from_numpy(self.xdata[x]), torch.from_numpy(self.ydata[x])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ydata)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_spec(cls, df: pd.DataFrame, pred_range: int=5):\n",
    "        from pgtaa import config as cfg\n",
    "        xdata, ydata = reshaped_data( \n",
    "            df=df,\n",
    "            window_size=cfg.WINDOW_SIZE, \n",
    "            pred_range=pred_range, \n",
    "            scaler=cfg.get_scaler()\n",
    "        )\n",
    "        return cls(xdata, ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = reshaped_data(df, pred_range=1, scaler=get_scaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3123, 32), (3021, 100, 32), (3021, 8))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.shape, x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_data(cfg.TRAIN_CSV, cfg.NB_ASSETS, return_array=False)\n",
    "train = x.iloc[:int(len(x)*0.8)]\n",
    "valid = x.iloc[int(len(x)*0.8):]\n",
    "ds_train = TimeSeriesDataset.from_spec(train, pred_range=5)\n",
    "ds_valid = TimeSeriesDataset.from_spec(valid, pred_range=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=1, shuffle=True, num_workers=2)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=1, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 200, Episodes: 200, Horizon: 30, Window Size: 100, Columns: 32\n"
     ]
    }
   ],
   "source": [
    "print(\"Epochs: {}, Episodes: {}, Horizon: {}, Window Size: {}, Columns: {}\".format(*p.pinit.windows.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2392it [00:47, 50.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01824203203251025, Validation Loss: 0.0008852243287006798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2392it [00:47, 50.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0023276667022716978, Validation Loss: 0.0005162613629408032\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from sklearn.svm import SVR\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.linear_model import SGDRegressor\n",
    "#from sklearn.manifold import TSNE\n",
    "#from sklearn.externals import joblib\n",
    "\n",
    "from pgtaa.core.predictor_preproc import dl_from_spec\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "max_epochs = 2\n",
    "dl_train, dl_valid = dl_from_spec(batch_size=1)\n",
    "\n",
    "# Linear network\n",
    "class PredDense(nn.Module):\n",
    "    def __init__(self, input_dim=3200, hidden_dim=(512, 128, 32), batch_size=1, output_dim=8):\n",
    "        super(PredDense, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_dim, hidden_dim[0])\n",
    "        self.lin2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
    "        self.lin3 = nn.Linear(hidden_dim[1], hidden_dim[2])\n",
    "        self.lin = nn.Linear(hidden_dim[2], output_dim, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.dropout = nn.Dropout(p=0.6, inplace=False)\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "    \n",
    "net = PredDense().double().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)   \n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(dl_train)):\n",
    "        inputs, label = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        # (seq_length,1,input_dim)\n",
    "        #x = x.view(len(x), self.batch_size, -1)\n",
    "        outputs = net(inputs.view(1,-1))\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # validation\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for j, vdata in enumerate(dl_valid):\n",
    "            vinput, vlabel = vdata[0].to(device), vdata[1].to(device)\n",
    "            outputs = net(vinput.view(1, -1))\n",
    "            loss = criterion(outputs, vlabel)\n",
    "            val_loss += loss.item()\n",
    "    print(f\"Train Loss: {train_loss / (i + 1)}, Validation Loss: {val_loss / (j + 1)}\")\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = list(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 100, 32]), torch.Size([1, 8]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl[0][0].shape, dl[0][1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fast1]",
   "language": "python",
   "name": "conda-env-fast1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
